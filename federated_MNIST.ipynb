{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FedMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jj1lAmf8nwN"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "from imutils import paths\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXUQP3ag_Pbh"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras import backend as K\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xthvs21tTSW"
      },
      "source": [
        "#Import ipynb file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Igu7oTHzoX0F",
        "outputId": "a942e21d-0ac1-42e2-a7e6-58dd48851afc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!pip install import-ipynb\n",
        "import import_ipynb\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Copy the link and remove the front part of the link (i.e. https://drive.google.com/open?id=) to get the file ID.\n",
        "your_module = drive.CreateFile({'id':'19XOxqFe7EA8WJ5Yd522iZYqPvHDNZ9Kb'})\n",
        "your_module.GetContentFile('federated_implementation_utils.ipynb')\n",
        "from federated_implementation_utils import *"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: import-ipynb in /usr/local/lib/python3.6/dist-packages (0.1.3)\n",
            "importing Jupyter notebook from federated_implementation_utils.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9tTxhrVt4wr"
      },
      "source": [
        "#declear path to your mnist data folder\n",
        "img_path = '/content/drive/My Drive/295-1/archive.zip (Unzipped Files)/trainingSample/trainingSample'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcl18IxjtH9r"
      },
      "source": [
        "#get the path list using the path object\n",
        "image_paths = list(paths.list_images(img_path))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3EMkfwgtKBn",
        "outputId": "7bdea0f2-8557-472f-a9a9-cc69e95118a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "#apply our function\n",
        "image_list, label_list = load(image_paths, verbose=50)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] processed 50/600\n",
            "[INFO] processed 100/600\n",
            "[INFO] processed 150/600\n",
            "[INFO] processed 200/600\n",
            "[INFO] processed 250/600\n",
            "[INFO] processed 300/600\n",
            "[INFO] processed 350/600\n",
            "[INFO] processed 400/600\n",
            "[INFO] processed 450/600\n",
            "[INFO] processed 500/600\n",
            "[INFO] processed 550/600\n",
            "[INFO] processed 600/600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU3nfRyktQ-3"
      },
      "source": [
        "#binarize the labels\n",
        "lb = LabelBinarizer()\n",
        "label_list = lb.fit_transform(label_list)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBfF7xZau0BH"
      },
      "source": [
        "#split data into training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_list, \n",
        "                                                    label_list, \n",
        "                                                    test_size=0.1, \n",
        "                                                    random_state=42)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsY4Ihx_u6GC"
      },
      "source": [
        "#create clients\n",
        "clients = create_clients(X_train, y_train, num_clients=5, initial='client')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-wtaq5-u9_d"
      },
      "source": [
        "#process and batch the training data for each client\n",
        "clients_batched = dict()\n",
        "for (client_name, data) in clients.items():\n",
        "    clients_batched[client_name] = batch_data(data)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TixiLT3dvEhl"
      },
      "source": [
        "#process and batch the test set  \n",
        "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5YiJQXdvH-c"
      },
      "source": [
        "comms_round = 100"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDxjW49Nvm5B"
      },
      "source": [
        "#create optimizer\n",
        "lr = 0.01 \n",
        "loss='categorical_crossentropy'\n",
        "metrics = ['accuracy']\n",
        "optimizer = SGD(lr=lr, \n",
        "                decay=lr / comms_round, \n",
        "                momentum=0.9\n",
        "               ) "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_Buh3QHvvrl"
      },
      "source": [
        "#initialize global model\n",
        "smlp_global = SimpleMLP()\n",
        "global_model = smlp_global.build(784, 10)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj8cv2sZvxzR",
        "outputId": "5c8779ba-2dd5-492c-ed08-95064cfb0e22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#commence global training loop\n",
        "for comm_round in range(comms_round):\n",
        "            \n",
        "    # get the global model's weights - will serve as the initial weights for all local models\n",
        "    global_weights = global_model.get_weights()\n",
        "    \n",
        "    #initial list to collect local model weights after scalling\n",
        "    scaled_local_weight_list = list()\n",
        "\n",
        "    #randomize client data - using keys\n",
        "    client_names= list(clients_batched.keys())\n",
        "    random.shuffle(client_names)\n",
        "    \n",
        "    #loop through each client and create new local model\n",
        "    for client in client_names:\n",
        "        smlp_local = SimpleMLP()\n",
        "        local_model = smlp_local.build(784, 10)\n",
        "        local_model.compile(loss=loss, \n",
        "                      optimizer=optimizer, \n",
        "                      metrics=metrics)\n",
        "        \n",
        "        #set local model weight to the weight of the global model\n",
        "        local_model.set_weights(global_weights)\n",
        "        \n",
        "        #fit local model with client's data\n",
        "        local_model.fit(clients_batched[client], epochs=1, verbose=0)\n",
        "        \n",
        "        #scale the model weights and add to list\n",
        "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
        "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
        "        scaled_local_weight_list.append(scaled_weights)\n",
        "        \n",
        "        #clear session to free memory after each communication round\n",
        "        K.clear_session()\n",
        "        \n",
        "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
        "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
        "    \n",
        "    #update global model \n",
        "    global_model.set_weights(average_weights)\n",
        "\n",
        "    #test global model and print out metrics after each communications round\n",
        "    for(X_test, Y_test) in test_batched:\n",
        "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round,False)\n",
        "        SGD_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(y_train)).batch(320)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "comm_round: 0 | global_acc: 28.333% | global_loss: 2.2875120639801025\n",
            "comm_round: 1 | global_acc: 36.667% | global_loss: 2.2818262577056885\n",
            "comm_round: 2 | global_acc: 40.000% | global_loss: 2.2755138874053955\n",
            "comm_round: 3 | global_acc: 43.333% | global_loss: 2.268787384033203\n",
            "comm_round: 4 | global_acc: 50.000% | global_loss: 2.261622428894043\n",
            "comm_round: 5 | global_acc: 55.000% | global_loss: 2.254131555557251\n",
            "comm_round: 6 | global_acc: 60.000% | global_loss: 2.245543956756592\n",
            "comm_round: 7 | global_acc: 61.667% | global_loss: 2.236078977584839\n",
            "comm_round: 8 | global_acc: 63.333% | global_loss: 2.226475477218628\n",
            "comm_round: 9 | global_acc: 68.333% | global_loss: 2.216399908065796\n",
            "comm_round: 10 | global_acc: 71.667% | global_loss: 2.2056996822357178\n",
            "comm_round: 11 | global_acc: 71.667% | global_loss: 2.193910837173462\n",
            "comm_round: 12 | global_acc: 71.667% | global_loss: 2.1815361976623535\n",
            "comm_round: 13 | global_acc: 73.333% | global_loss: 2.1690993309020996\n",
            "comm_round: 14 | global_acc: 73.333% | global_loss: 2.156804323196411\n",
            "comm_round: 15 | global_acc: 73.333% | global_loss: 2.142610788345337\n",
            "comm_round: 16 | global_acc: 71.667% | global_loss: 2.1288697719573975\n",
            "comm_round: 17 | global_acc: 71.667% | global_loss: 2.1138787269592285\n",
            "comm_round: 18 | global_acc: 71.667% | global_loss: 2.10042667388916\n",
            "comm_round: 19 | global_acc: 71.667% | global_loss: 2.0864691734313965\n",
            "comm_round: 20 | global_acc: 73.333% | global_loss: 2.0717387199401855\n",
            "comm_round: 21 | global_acc: 73.333% | global_loss: 2.0580925941467285\n",
            "comm_round: 22 | global_acc: 73.333% | global_loss: 2.044780969619751\n",
            "comm_round: 23 | global_acc: 75.000% | global_loss: 2.0315334796905518\n",
            "comm_round: 24 | global_acc: 75.000% | global_loss: 2.0184485912323\n",
            "comm_round: 25 | global_acc: 73.333% | global_loss: 2.0052616596221924\n",
            "comm_round: 26 | global_acc: 73.333% | global_loss: 1.9951170682907104\n",
            "comm_round: 27 | global_acc: 73.333% | global_loss: 1.9828284978866577\n",
            "comm_round: 28 | global_acc: 73.333% | global_loss: 1.9712367057800293\n",
            "comm_round: 29 | global_acc: 73.333% | global_loss: 1.961682677268982\n",
            "comm_round: 30 | global_acc: 73.333% | global_loss: 1.9514052867889404\n",
            "comm_round: 31 | global_acc: 71.667% | global_loss: 1.9433369636535645\n",
            "comm_round: 32 | global_acc: 71.667% | global_loss: 1.934934139251709\n",
            "comm_round: 33 | global_acc: 71.667% | global_loss: 1.9259448051452637\n",
            "comm_round: 34 | global_acc: 73.333% | global_loss: 1.9190590381622314\n",
            "comm_round: 35 | global_acc: 71.667% | global_loss: 1.9103882312774658\n",
            "comm_round: 36 | global_acc: 73.333% | global_loss: 1.9033386707305908\n",
            "comm_round: 37 | global_acc: 73.333% | global_loss: 1.896348476409912\n",
            "comm_round: 38 | global_acc: 73.333% | global_loss: 1.8899186849594116\n",
            "comm_round: 39 | global_acc: 73.333% | global_loss: 1.8849879503250122\n",
            "comm_round: 40 | global_acc: 73.333% | global_loss: 1.8795186281204224\n",
            "comm_round: 41 | global_acc: 73.333% | global_loss: 1.8744282722473145\n",
            "comm_round: 42 | global_acc: 73.333% | global_loss: 1.8686827421188354\n",
            "comm_round: 43 | global_acc: 73.333% | global_loss: 1.8644068241119385\n",
            "comm_round: 44 | global_acc: 73.333% | global_loss: 1.859117865562439\n",
            "comm_round: 45 | global_acc: 73.333% | global_loss: 1.854725956916809\n",
            "comm_round: 46 | global_acc: 73.333% | global_loss: 1.850951910018921\n",
            "comm_round: 47 | global_acc: 73.333% | global_loss: 1.846746802330017\n",
            "comm_round: 48 | global_acc: 71.667% | global_loss: 1.8429607152938843\n",
            "comm_round: 49 | global_acc: 71.667% | global_loss: 1.839257001876831\n",
            "comm_round: 50 | global_acc: 73.333% | global_loss: 1.83558988571167\n",
            "comm_round: 51 | global_acc: 71.667% | global_loss: 1.8330837488174438\n",
            "comm_round: 52 | global_acc: 71.667% | global_loss: 1.830129861831665\n",
            "comm_round: 53 | global_acc: 73.333% | global_loss: 1.8272769451141357\n",
            "comm_round: 54 | global_acc: 71.667% | global_loss: 1.8246690034866333\n",
            "comm_round: 55 | global_acc: 71.667% | global_loss: 1.822482943534851\n",
            "comm_round: 56 | global_acc: 71.667% | global_loss: 1.8194785118103027\n",
            "comm_round: 57 | global_acc: 71.667% | global_loss: 1.8154524564743042\n",
            "comm_round: 58 | global_acc: 71.667% | global_loss: 1.813127875328064\n",
            "comm_round: 59 | global_acc: 71.667% | global_loss: 1.8108011484146118\n",
            "comm_round: 60 | global_acc: 71.667% | global_loss: 1.8097119331359863\n",
            "comm_round: 61 | global_acc: 71.667% | global_loss: 1.8078173398971558\n",
            "comm_round: 62 | global_acc: 70.000% | global_loss: 1.8057152032852173\n",
            "comm_round: 63 | global_acc: 71.667% | global_loss: 1.8029677867889404\n",
            "comm_round: 64 | global_acc: 71.667% | global_loss: 1.800596833229065\n",
            "comm_round: 65 | global_acc: 71.667% | global_loss: 1.7992074489593506\n",
            "comm_round: 66 | global_acc: 71.667% | global_loss: 1.797970175743103\n",
            "comm_round: 67 | global_acc: 71.667% | global_loss: 1.795601725578308\n",
            "comm_round: 68 | global_acc: 71.667% | global_loss: 1.794206976890564\n",
            "comm_round: 69 | global_acc: 71.667% | global_loss: 1.7923569679260254\n",
            "comm_round: 70 | global_acc: 71.667% | global_loss: 1.7909164428710938\n",
            "comm_round: 71 | global_acc: 71.667% | global_loss: 1.7894549369812012\n",
            "comm_round: 72 | global_acc: 71.667% | global_loss: 1.7874610424041748\n",
            "comm_round: 73 | global_acc: 71.667% | global_loss: 1.785754919052124\n",
            "comm_round: 74 | global_acc: 73.333% | global_loss: 1.7847272157669067\n",
            "comm_round: 75 | global_acc: 71.667% | global_loss: 1.7831885814666748\n",
            "comm_round: 76 | global_acc: 71.667% | global_loss: 1.7827099561691284\n",
            "comm_round: 77 | global_acc: 71.667% | global_loss: 1.7817059755325317\n",
            "comm_round: 78 | global_acc: 71.667% | global_loss: 1.7807637453079224\n",
            "comm_round: 79 | global_acc: 73.333% | global_loss: 1.7778939008712769\n",
            "comm_round: 80 | global_acc: 73.333% | global_loss: 1.7765839099884033\n",
            "comm_round: 81 | global_acc: 73.333% | global_loss: 1.7761598825454712\n",
            "comm_round: 82 | global_acc: 73.333% | global_loss: 1.7745956182479858\n",
            "comm_round: 83 | global_acc: 73.333% | global_loss: 1.7732948064804077\n",
            "comm_round: 84 | global_acc: 73.333% | global_loss: 1.7714794874191284\n",
            "comm_round: 85 | global_acc: 73.333% | global_loss: 1.7709541320800781\n",
            "comm_round: 86 | global_acc: 73.333% | global_loss: 1.770001769065857\n",
            "comm_round: 87 | global_acc: 73.333% | global_loss: 1.7687510251998901\n",
            "comm_round: 88 | global_acc: 75.000% | global_loss: 1.7679344415664673\n",
            "comm_round: 89 | global_acc: 75.000% | global_loss: 1.7675527334213257\n",
            "comm_round: 90 | global_acc: 76.667% | global_loss: 1.7653599977493286\n",
            "comm_round: 91 | global_acc: 73.333% | global_loss: 1.7650667428970337\n",
            "comm_round: 92 | global_acc: 76.667% | global_loss: 1.7641148567199707\n",
            "comm_round: 93 | global_acc: 76.667% | global_loss: 1.7629342079162598\n",
            "comm_round: 94 | global_acc: 76.667% | global_loss: 1.7623969316482544\n",
            "comm_round: 95 | global_acc: 76.667% | global_loss: 1.7614476680755615\n",
            "comm_round: 96 | global_acc: 76.667% | global_loss: 1.7607661485671997\n",
            "comm_round: 97 | global_acc: 76.667% | global_loss: 1.759611964225769\n",
            "comm_round: 98 | global_acc: 76.667% | global_loss: 1.7587165832519531\n",
            "comm_round: 99 | global_acc: 76.667% | global_loss: 1.757587194442749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osfr7qjqv_uN"
      },
      "source": [
        "smlp_SGD = SimpleMLP()\n",
        "SGD_model = smlp_SGD.build(784, 10) "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY88mvh7wnSA"
      },
      "source": [
        "SGD_model.compile(loss=loss, \n",
        "              optimizer=optimizer, \n",
        "              metrics=metrics)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLAPfDhTwpWe"
      },
      "source": [
        "# fit the SGD training data to model\n",
        "_ = SGD_model.fit(SGD_dataset, epochs=100, verbose=0)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbUYoMi_wrnS",
        "outputId": "f9fc6ec9-6f54-47d4-b81b-6d24604acfc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "source": [
        "#test the SGD global model and print out metrics\n",
        "for(X_test, Y_test) in test_batched:\n",
        "        SGD_acc, SGD_loss = test_model(X_test, Y_test, SGD_model, 1,True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[1 7 9 1 3 4 0 6 1 5 0 1 1 9 7 3 0 3 3 1 0 9 8 9 7 8 1 2 9 6 9 2 1 4 3 6 2\n",
            " 8 6 4 7 0 8 9 0 3 6 1 1 8 4 4 1 9 9 5 3 2 2 3], shape=(60,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[1 9 9 1 2 4 0 6 1 1 0 1 1 9 7 9 0 3 3 1 0 9 4 5 7 3 5 2 9 6 9 2 1 6 3 6 6\n",
            " 8 6 4 7 0 8 9 0 3 6 1 1 5 4 4 1 9 9 5 9 2 2 3], shape=(60,), dtype=int64)\n",
            "comm_round: 1 | global_acc: 80.000% | global_loss: 1.7105252742767334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPqULlDRxKUy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}